{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 减少内存位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码的目的是减少DataFrame的内存占用。它首先计算DataFrame的初始内存大小，并遍历所有列，检查它们的数据类型。如果列的数据类型是整数或浮点数，它将尝试将列转换为更小的数据类型，以减少内存使用。\n",
    "\n",
    "代码逻辑如下：\n",
    "\n",
    "1. 定义一个列表`numerics`，包含了所有需要检查的数值数据类型。\n",
    "2. 计算DataFrame `df`的初始内存使用量`start_mem`。\n",
    "3. 遍历DataFrame的所有列，对于每一列：\n",
    "    - 获取列的数据类型`col_type`。\n",
    "    - 如果`col_type`是数值类型之一：\n",
    "        - 计算列的最小值`c_min`和最大值`c_max`。\n",
    "        - 如果`col_type`是整数类型：\n",
    "            - 根据`c_min`和`c_max`的值，尝试将列转换为`np.int8`、`np.int16`、`np.int32`或`np.int64`中的一个更小的整数类型。\n",
    "        - 如果`col_type`是浮点类型：\n",
    "            - 计算列的最大精度`c_prec`。\n",
    "            - 根据`c_min`、`c_max`和`c_prec`的值，尝试将列转换为`np.float16`、`np.float32`或保留为`np.float64`中的一个更小的浮点类型。\n",
    "4. 计算转换后的DataFrame `df`的内存使用量`end_mem`。\n",
    "5. 如果`verbose`参数为True，打印内存使用量减少的信息，包括减少的百分比。\n",
    "\n",
    "总的来说，这个函数通过转换DataFrame中的列到更小的数据类型来减少内存占用，特别是对于包含大量数值数据的大型DataFrame，这可以带来显著的内存节省。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编码拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df,test_df],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这行代码是Pandas库中的一段代码，它的功能是将两个DataFrame对象 `train_df` 和 `test_df` 沿着轴合并，并重新设置索引。\n",
    "\n",
    "1. `pd.concat()` 函数是Pandas中用来合并两个或多个DataFrame或Series的函数。这里，它被用来合并 `train_df` 和 `test_df` 这两个DataFrame。\n",
    "\n",
    "2. `axis=0` 参数指定了合并的轴。在这个例子中，`axis=0` 表示沿着行的方向（垂直方向）合并，即将 `test_df` 放在 `train_df` 的下方。如果设置为 `axis=1`，则会沿着列的方向（水平方向）合并，即将 `test_df` 放在 `train_df` 的右侧。\n",
    "\n",
    "3. `reset_index()` 函数用来重置DataFrame的索引。在合并两个DataFrame之后，每个原始DataFrame的索引都会保留在结果DataFrame中，这可能会导致索引重复。为了避免这个问题，`reset_index()` 会重新为合并后的DataFrame生成一个新的连续索引。\n",
    "\n",
    "4. `drop=True` 参数指定了在重置索引时，是否丢弃原来的索引。如果设置为 `True`，那么原来的索引会被丢弃，不会成为结果DataFrame的一列。如果设置为 `False`，原来的索引会被保留并作为一个新的列添加到结果DataFrame中。\n",
    "\n",
    "综上所述，这行代码的整体作用是将 `train_df` 和 `test_df` 这两个DataFrame垂直方向合并成一个新的DataFrame，并为这个新的DataFrame生成一组新的连续索引，同时丢弃原来的"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
